# ğŸ¤ AuraCalm â€“ Your AI-Powered Pocket Guide to Calm  

**AuraCalm detects vocal stress in real time and instantly delivers soothing soundscapes, gentle haptics, and calming visualsâ€”helping you restore balance anytime, anywhere.**  

---

## âœ¨ Features  

- ğŸ™ï¸ **Voice Stress Detection** â€“ Analyze vocal patterns in real-time to detect stress.  
- ğŸ¶ **Soothing Soundscapes** â€“ Automatically play calming background music tailored to stress levels.  
- ğŸ“³ **Gentle Haptics** â€“ Deliver subtle vibration feedback to ground and relax users.  
- ğŸŒˆ **Calming Visuals** â€“ On-screen animations that promote relaxation.  
- âš¡ **Instant Feedback** â€“ Works in real-time for on-the-go stress relief.  

---

## ğŸ› ï¸ Built With  

**Next.js 14 | TypeScript | Tailwind CSS | Framer Motion | Web Audio API | Navigator Vibration API | HTML5 | CSS3 | Node.js | Vercel**  

---

## ğŸ“¸ Screenshots  

> *(Add demo screenshots or GIFs of AuraCalm here)*  

---

## ğŸš€ Getting Started  

### Prerequisites  
- Node.js (>= 18)  
- npm / yarn / pnpm  

### Installation  

```bash
# Clone the repository
git clone https://github.com/your-username/auracalm.git

# Navigate to the project
cd auracalm

# Install dependencies
npm install

# Start the development server
npm run dev
The app will be live at http://localhost:3000/
```

## ğŸ“¦ Deployment

Easily deployed on Vercel with zero-config hosting.
```bash
npm run build
npm run start
```

## ğŸ“š Project Story

## ğŸ¯ Inspiration
Stress and anxiety are increasing in todayâ€™s fast-paced world. We wanted to create an AI-driven, real-time companion that helps people regain calm through sound, touch, and visuals.

## ğŸ› ï¸ How We Built It
~ Next.js + TypeScript for a scalable front-end.
~ Tailwind CSS + Framer Motion for a sleek, animated interface.
~ Web Audio API for generating soothing soundscapes.
~ Navigator Vibration API for subtle haptic feedback.
~ Hosted on Vercel for fast deployment.

## ğŸš§ Challenges We Faced
~ Extracting meaningful vocal stress signals.
~ Combining audio, visuals, and haptics in sync.
~ Creating a lightweight yet engaging experience.

## ğŸ“– What We Learned
~ Leveraging modern browser APIs for wellness apps.
~ Importance of multisensory feedback in stress reduction.
~ Designing calming UI/UX with accessibility in mind.

## ğŸŒŸ Whatâ€™s Next
~ AI-based personalized stress detection & recommendations.
~ Mobile-first PWA version for offline access.
~ Integration with wearables for biofeedback (heart rate, skin response).

##ğŸ¤ Contributing

We welcome contributions! ğŸŒ±
~ Fork the repo
~ Create your feature branch (git checkout -b feature/new-feature)
~ Commit your changes (git commit -m 'Add new feature')
~ Push to the branch (git push origin feature/new-feature)
~ Open a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License â€“ see the LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Team

Rudraksh Tripathi â€“ Developer & Project Lead
Barkha Gupta - Developer

